{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:Lora; text-align: center;\"> You will need to enter both your AWS Access Key and AWS Secret Access Key</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY = '----FILL IN----'\n",
    "AWS_SECRET_ACCESS_KEY ='----FILL IN----'\n",
    "AWS_REGION = 'eu-west-1'\n",
    " \n",
    "client_comprehend = boto3.client(\n",
    "    'comprehend',\n",
    "    region_name = AWS_REGION ,\n",
    "    aws_access_key_id = AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key = AWS_SECRET_ACCESS_KEY    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(file):\n",
    "    with open(file) as data_file:    \n",
    "        data = json.load(data_file)\n",
    "        return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the movie La Llorona, the mean lexicon count was 24.5, the mean sentence count was 1.56, the mean flesch reading ease score was 67.8462, and the mean flesch_kincaid grade level was 7.950000000000002.\n"
     ]
    }
   ],
   "source": [
    "def getReadability(movie_title, the_file, start_tweet_num, end_tweet_num):\n",
    "   movie_df = make_df(the_file)\n",
    "   movie_tweet_list = movie_df['text'].tolist()\n",
    "   num_tweets = end_tweet_num - start_tweet_num\n",
    "\n",
    "   lexicon_count = 0\n",
    "   sentence_count = 0\n",
    "   flesch_ease = 0\n",
    "   flesch_kincaid = 0\n",
    "\n",
    "\n",
    "   for i in movie_tweet_list[start_tweet_num: end_tweet_num]:\n",
    "\n",
    "       lexicon_count += textstat.lexicon_count(i, removepunct=True)\n",
    "       sentence_count += textstat.sentence_count(i)\n",
    "       flesch_ease += textstat.flesch_reading_ease(i)\n",
    "       flesch_kincaid += textstat.flesch_kincaid_grade(i)\n",
    "\n",
    "\n",
    "   mean_lexicon = lexicon_count / num_tweets  # Insert num tweets instead of 50 once testing complete.\n",
    "   mean_sentence = sentence_count / num_tweets\n",
    "   mean_flesch = flesch_ease / num_tweets\n",
    "   mean_flesch_kincaid = flesch_kincaid / num_tweets\n",
    "\n",
    "\n",
    "   print('For the movie ' + movie_title + ', the mean lexicon count was ' + str(mean_lexicon) +\n",
    "         ', the mean sentence count was ' + str(mean_sentence) + ', the mean flesch reading ease score was ' +\n",
    "         str(mean_flesch) + ', and the mean flesch_kincaid grade level was ' + str(mean_flesch_kincaid) + '.')\n",
    "\n",
    "getReadability('La Llorona', 'FINAL_CLEANED_DATASETS/JSON_FILES/Lallorona.json', 0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the movie La Llorona, 12.0% of tweets were positive (average confidence score was 0.15814473159145565), 22.0% negative (average confidence score was 0.21091976046685887),64.0% neutral (average confidence score was 0.576182504100725), and 2.0% mixed (average confidence score was 0.05475300889229402).\n"
     ]
    }
   ],
   "source": [
    "def getSentiment(movie_title, the_file, start_tweet_num, end_tweet_num):\n",
    "    movie_df = make_df(the_file)\n",
    "    movie_tweet_list = movie_df['text'].tolist()\n",
    "    num_tweets = end_tweet_num - start_tweet_num\n",
    "    \n",
    "    num_negative = 0\n",
    "    num_positive = 0\n",
    "    num_neutral = 0\n",
    "    num_mixed = 0 \n",
    "    \n",
    "    confidence_neg_sentiment_of_tweet = 0\n",
    "    confidence_pos_sentiment_of_tweet = 0\n",
    "    confidence_neu_sentiment_of_tweet = 0\n",
    "    confidence_mix_sentiment_of_tweet = 0\n",
    "    \n",
    "    for i in movie_tweet_list[start_tweet_num : end_tweet_num]:\n",
    "        response_sentiment = client_comprehend.detect_sentiment(\n",
    "            Text=i,\n",
    "            LanguageCode='en'\n",
    "        )\n",
    "        sentiment = response_sentiment['Sentiment']\n",
    "            \n",
    "        if sentiment == 'NEGATIVE': \n",
    "            num_negative += 1\n",
    "            \n",
    "        elif sentiment == 'POSITIVE': \n",
    "            num_positive += 1\n",
    "            \n",
    "        elif sentiment == 'NEUTRAL': \n",
    "            num_neutral += 1\n",
    "            \n",
    "        elif sentiment == 'MIXED': \n",
    "            num_mixed += 1\n",
    "            \n",
    "        sentiment_score = response_sentiment['SentimentScore']\n",
    "        confidence_neg_sentiment_of_tweet += sentiment_score['Negative']\n",
    "        confidence_pos_sentiment_of_tweet += sentiment_score['Positive']\n",
    "        confidence_neu_sentiment_of_tweet += sentiment_score['Neutral']\n",
    "        confidence_mix_sentiment_of_tweet += sentiment_score['Mixed']\n",
    "        \n",
    "    mean_negative_confidence = confidence_neg_sentiment_of_tweet/num_tweets #Insert num tweets instead of 50 once testing complete. \n",
    "    mean_positive_confidence = confidence_pos_sentiment_of_tweet/num_tweets\n",
    "    mean_neutral_confidence = confidence_neu_sentiment_of_tweet/num_tweets\n",
    "    mean_mixed_confidence = confidence_mix_sentiment_of_tweet/num_tweets\n",
    "    \n",
    "    percent_negative = str(((num_negative / num_tweets)* 100)) + '\\u0025'\n",
    "    percent_positive = str(((num_positive / num_tweets) * 100)) + '\\u0025'\n",
    "    percent_neutral = str(((num_neutral / num_tweets) * 100)) + '\\u0025'\n",
    "    percent_mixed = str(((num_mixed / num_tweets) * 100)) + '\\u0025'\n",
    "    \n",
    "    print('For the movie ' + movie_title + ', ' + percent_positive  + \n",
    "          ' of tweets were positive \\u0028average confidence score was ' + str(mean_positive_confidence) + '\\u0029, '\n",
    "          + percent_negative + ' negative \\u0028average confidence score was ' + str(mean_negative_confidence) + '\\u0029,'\n",
    "          + percent_neutral + ' neutral \\u0028average confidence score was ' + str(mean_neutral_confidence) + '\\u0029, and '\n",
    "          + percent_mixed + ' mixed \\u0028average confidence score was ' + str(mean_mixed_confidence) + '\\u0029.')\n",
    "    \n",
    "getSentiment('La Llorona', 'FINAL_CLEANED_DATASETS/JSON_FILES/Lallorona.json', 0, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
